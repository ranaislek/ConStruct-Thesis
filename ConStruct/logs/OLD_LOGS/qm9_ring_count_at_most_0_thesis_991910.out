torch version: 2.0.1+cu118
CUDA available: True
CUDA device: NVIDIA RTX A5000
=== Running Experiment: ring_count_at_most_0_thesis ===
Config: thesis/edge_deletion/ring_count_at_most/qm9_thesis_ring_count_at_most_0
Job ID: 991910
Node: vgpu0-1
Time: Sun 10 Aug 2025 08:36:34 PM UTC
<frozen importlib._bootstrap>:228: RuntimeWarning: to-Python converter for std::pair<double, double> already registered; second conversion method ignored.
[rank: 0] Global seed set to 0
Loading reference metrics.
Edge-deletion transition model (for 'at most' constraints)
[INFO] Early stopping enabled: monitoring 'val/epoch_NLL' with patience 30
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Global seed set to 0
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
[2025-08-10 20:36:43,405][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-08-10 20:36:43,406][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/rislek/.conda/envs/construct-env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory checkpoints/qm9_thesis_ring_count_at_most_0 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                  | Type                  | Params
----------------------------------------------------------------
0 | train_loss            | TrainLoss             | 0     
1 | train_metrics         | TrainMolecularMetrics | 0     
2 | val_metrics           | MetricCollection      | 0     
3 | val_nll               | NLL                   | 0     
4 | val_sampling_metrics  | SamplingMetrics       | 0     
5 | test_metrics          | MetricCollection      | 0     
6 | test_nll              | NLL                   | 0     
7 | test_sampling_metrics | SamplingMetrics       | 0     
8 | model                 | GraphTransformer      | 3.5 M 
----------------------------------------------------------------
3.5 M     Trainable params
0         Non-trainable params
3.5 M     Total params
13.901    Total estimated model params size (MB)
wandb: Currently logged in as: islekrana (islekrana-universit-di-padova). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.21.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /extra/rislek/ConStruct-Thesis/ConStruct/wandb/run-20250810_203645-piz2c4kj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qm9_thesis_ring_count_at_most_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/islekrana-universit-di-padova/ConStruct_qm9
wandb: üöÄ View run at https://wandb.ai/islekrana-universit-di-padova/ConStruct_qm9/runs/piz2c4kj
SLURM auto-requeueing enabled. Setting signal handlers.
Epoch 0: val/epoch_NLL: 279.43 -- val/X_kl: 5.66 -- val/E_kl: 254.33 -- val/charges_kl: 14.77 
Val loss: 279.4257 	 Best val loss:  279.4257

Val epoch 0 ends
Starting epoch 0
[2025-08-10 20:36:54,511][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
Train epoch 0 ends
Epoch 0 finished: X: 0.53 -- charges: 0.10 -- E: 0.41 -- y: -1.00 -- 148.5s 
Epoch 0: {'CarbonCE': 0.405, 'NitroCE': 0.244, 'OxyCE': 0.293, 'FluorCE': 0.015} -- {'NoBondCE': 0.345, 'SingleCE': 0.322, 'DoubleCE': 0.068, 'TripleCE': 0.027, 'AromaticCE': 0.004}
Starting epoch 1
Train epoch 1 ends
Epoch 1 finished: X: 0.48 -- charges: 0.08 -- E: 0.39 -- y: -1.00 -- 133.8s 
Epoch 1: {'CarbonCE': 0.373, 'NitroCE': 0.223, 'OxyCE': 0.268, 'FluorCE': 0.01} -- {'NoBondCE': 0.33, 'SingleCE': 0.309, 'DoubleCE': 0.061, 'TripleCE': 0.022, 'AromaticCE': 0.0}
Starting epoch 2
Train epoch 2 ends
Epoch 2 finished: X: 0.48 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 134.3s 
Epoch 2: {'CarbonCE': 0.368, 'NitroCE': 0.22, 'OxyCE': 0.265, 'FluorCE': 0.01} -- {'NoBondCE': 0.328, 'SingleCE': 0.307, 'DoubleCE': 0.06, 'TripleCE': 0.022, 'AromaticCE': 0.0}
Starting epoch 3
Train epoch 3 ends
Epoch 3 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 132.7s 
Epoch 3: {'CarbonCE': 0.365, 'NitroCE': 0.217, 'OxyCE': 0.263, 'FluorCE': 0.01} -- {'NoBondCE': 0.325, 'SingleCE': 0.304, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 4
Train epoch 4 ends
Epoch 4 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 134.0s 
Epoch 4: {'CarbonCE': 0.365, 'NitroCE': 0.217, 'OxyCE': 0.263, 'FluorCE': 0.009} -- {'NoBondCE': 0.324, 'SingleCE': 0.303, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 5
Train epoch 5 ends
Epoch 5 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.1s 
Epoch 5: {'CarbonCE': 0.363, 'NitroCE': 0.216, 'OxyCE': 0.263, 'FluorCE': 0.009} -- {'NoBondCE': 0.324, 'SingleCE': 0.303, 'DoubleCE': 0.06, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 6
Train epoch 6 ends
Epoch 6 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.6s 
Epoch 6: {'CarbonCE': 0.363, 'NitroCE': 0.216, 'OxyCE': 0.262, 'FluorCE': 0.009} -- {'NoBondCE': 0.324, 'SingleCE': 0.303, 'DoubleCE': 0.06, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 7
Train epoch 7 ends
Epoch 7 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 134.0s 
Epoch 7: {'CarbonCE': 0.36, 'NitroCE': 0.215, 'OxyCE': 0.26, 'FluorCE': 0.009} -- {'NoBondCE': 0.323, 'SingleCE': 0.302, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 8
Train epoch 8 ends
Epoch 8 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 134.0s 
Epoch 8: {'CarbonCE': 0.361, 'NitroCE': 0.214, 'OxyCE': 0.261, 'FluorCE': 0.009} -- {'NoBondCE': 0.322, 'SingleCE': 0.301, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 9
Train epoch 9 ends
Epoch 9 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 134.3s 
Epoch 9: {'CarbonCE': 0.361, 'NitroCE': 0.215, 'OxyCE': 0.261, 'FluorCE': 0.009} -- {'NoBondCE': 0.322, 'SingleCE': 0.302, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 10
Train epoch 10 ends
Epoch 10 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.2s 
Epoch 10: {'CarbonCE': 0.362, 'NitroCE': 0.215, 'OxyCE': 0.261, 'FluorCE': 0.009} -- {'NoBondCE': 0.323, 'SingleCE': 0.303, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 11
Train epoch 11 ends
Epoch 11 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.1s 
Epoch 11: {'CarbonCE': 0.359, 'NitroCE': 0.214, 'OxyCE': 0.259, 'FluorCE': 0.009} -- {'NoBondCE': 0.321, 'SingleCE': 0.301, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 12
Train epoch 12 ends
Epoch 12 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.2s 
Epoch 12: {'CarbonCE': 0.359, 'NitroCE': 0.214, 'OxyCE': 0.259, 'FluorCE': 0.009} -- {'NoBondCE': 0.321, 'SingleCE': 0.301, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 13
Train epoch 13 ends
Epoch 13 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.5s 
Epoch 13: {'CarbonCE': 0.359, 'NitroCE': 0.214, 'OxyCE': 0.259, 'FluorCE': 0.009} -- {'NoBondCE': 0.321, 'SingleCE': 0.3, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 14
Train epoch 14 ends
Epoch 14 finished: X: 0.47 -- charges: 0.08 -- E: 0.38 -- y: -1.00 -- 133.3s 
Epoch 14: {'CarbonCE': 0.359, 'NitroCE': 0.214, 'OxyCE': 0.259, 'FluorCE': 0.009} -- {'NoBondCE': 0.321, 'SingleCE': 0.3, 'DoubleCE': 0.059, 'TripleCE': 0.021, 'AromaticCE': 0.0}
Starting epoch 15
slurmstepd-vgpu0-1: error: *** JOB 991910 ON vgpu0-1 CANCELLED AT 2025-08-10T21:12:13 ***
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
wandb: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe
